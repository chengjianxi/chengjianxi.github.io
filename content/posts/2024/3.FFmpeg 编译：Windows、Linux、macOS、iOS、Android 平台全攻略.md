---
title: "FFmpeg 编译：Windows、Linux、macOS、iOS、Android 平台全攻略"
date: 2024-03-10T17:55:28+08:00
description: ""
tags: []
type: post
weight: 1
showTableOfContents: true
---

FFmpeg 是一个开源的音视频处理工具集，它包含了众多用于录制、转换和流式传输音视频的库和程序。它提供了一种强大而灵活的方式来处理各种音视频格式，可以进行音视频的编解码、转码、剪辑、合并、分割、过滤、流化等操作。FFmpeg 可以在多个平台上运行，包括 Windows、Mac OS X、Linux 等，因此被广泛应用于音视频处理、转换、编辑等领域。

<!--more-->

FFmpeg 是一个集成了多个库和工具的多媒体处理框架。其中一些主要的库包括：

- **libavcodec**：用于音频和视频编解码的核心库。它包含了众多编解码器的实现，例如 H.264、AAC、MP3 等。
- **libavformat**：用于音视频封装格式的处理，支持解析和封装各种音视频格式，包括 MPEG, AVI, MP4, FLV 等。
- **libavfilter**：用于音视频的过滤和处理，可以进行裁剪、调整大小、添加水印、色彩调整等操作。
- **libswscale**：用于图像缩放和颜色空间转换的库。
- **libavutil**：提供了一些常用的工具函数和数据结构，被其他库用作辅助功能。
- **libswresample**：用于音频重采样的库。

除了这些核心库之外，FFmpeg 还包括一些其他的辅助库和工具，如：

- **ffmpeg**：命令行工具，用于执行各种音视频处理任务。
- **ffplay**：简单的音视频播放器，可以播放各种格式的音视频文件。
- **ffprobe**：用于分析音视频文件的工具，可以提供文件的详细信息。

这些库和工具的组合使得 FFmpeg 成为一个功能强大且灵活的多媒体处理框架，可以用于各种音视频处理任务，如编解码、格式转换、流处理等。



## 1. Windows 编译

### 1.1. 使用 MSYS2 编译

要在 Windows 上编译 FFmpeg，可以使用 MSYS2 和 MinGW-w64。MSYS2是一个基于 Cygwin 的 Unix-like 环境，可以为 Windows 提供类似于 Linux 的开发环境。使用 MSYS2 来编译 FFmpeg，可以避免很多在 Windows 下编译 FFmpeg 时遇到的问题。

首先，从[MSYS2 官方网站](https://www.msys2.org/)下载并安装 MSYS2。然后，打开 MSYS2 的命令行工具。**不要直接在命令行中或使用快捷方式打开**。需要打开 `x64 Native Tools Command Prompt for VS 2022` 命令行（根据时间版本和平台），然后进入 msys 安装目录，输入 `msys2_shell.cmd -mingw64`  进入 MINGW64 命令行。

如果要使用 ` --toolchain=msvc ` 参数，则需要在 `msys2_shell.cmd -mingw64` 命令之前输入 `set MSYS2_PATH_TYPE=inherit` 命令。

输入 `echo $LIB` 可以看到 msys2 命令行窗口已经继承了 Visual Studio 的 library 环境变量。执行以下命令来安装依赖项：

```sh
pacman -Syu
pacman -Su
pacman -S mingw-w64-x86_64-toolchain
# 32 位需要
pacman -S mingw-w64-i686-toolchain
pacman -S base-devel
pacman -S yasm
pacman -S nasm
pacman -S gcc
pacman -S autoconf automake libtool
```



#### 1.1.1. 编译 libx264

https://www.videolan.org/developers/x264.html

libx264 提供了 H.264 视频编码功能，如果想在 FFmpeg 使用 libx264 需要再配置中添加 `--enable-gpl --enable-libx264` 参数。打开 MSYS2 的命令行工具，执行下列命令：

```shell
git clone https://code.videolan.org/videolan/x264.git
cd x264
./configure --prefix=/usr/local/x264 --enable-shared --enable-static
# 32 bit
./configure --prefix=/usr/local/x264-32 --enable-shared --enable-static --host=i686-w64-mingw32
make
sudo make install
```



#### 1.1.2. 编译 libx265

```shell
git clone https://github.com/videolan/x265
cd x265
git checkout 3.4
cd build
cmake ../source -DCMAKE_INSTALL_PREFIX="./out"
cmake --build . --config Release
cmake --install . --config Release
```





#### 1.1.3. 编译 FFmpeg

然后克隆 FFmpeg 存储库，可以在 Windows 克隆，也可以在 MSYS2 shell 中克隆：

```sh
git clone https://github.com/FFmpeg/FFmpeg.git
cd FFmpeg
# 切换分支
git checkout n6.1
```

最后就可以执行配置配置编译选项并编译了；

```sh
# 使用默认配置
./configure --prefix=/usr/local/ffmpeg --enable-shared
# haoxin codec config（启用 h264、启用 NVIDIA H264、启用 Intel QSV vp9）
PKG_CONFIG_PATH="/usr/local/x264/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/vpl/lib/pkgconfig:$PKG_CONFIG_PATH" ./configure --prefix=/usr/local/ffmpeg --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-decoder=rawvideo --enable-decoder=h264 --enable-decoder=h264_cuvid --enable-decoder=h264_qsv --enable-decoder=vp9_cuvid --enable-decoder=vp9_qsv --enable-encoder=libx264 --enable-encoder=h264_nvenc --enable-encoder=h264_qsv --enable-encoder=vp9_qsv --enable-hwaccel=h264_nvdec --enable-hwaccel=h264_d3d11va --enable-hwaccel=h264_d3d11va2 --enable-hwaccel=h264_dxva2 --enable-hwaccel=vp9_d3d11va --enable-hwaccel=vp9_d3d11va2 --enable-hwaccel=vp9_dxva2 --enable-hwaccel=vp9_nvdec --enable-muxer=h264 --enable-demuxer=rawvideo --enable-demuxer=h264 --enable-protocol=file --enable-filter=scale --enable-libx264 --enable-cuda --enable-cuvid --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --extra-ldflags='-Wl,-Bstatic -lpthread'
#--extra-cxxflags="-I/usr/local/x264/include" --extra-ldflags="-L/usr/local/x264/lib"
make -j
make install
```

`-Wl,-Bstatic -lpthread` 的参数的意思编译时静态引用 *pthread*，这样发布时就不用附带 *libwinpthread-1.dll* 这个动态库了。

编译安装完成后，在 msys 的安装目录下可以在找到编译出来的库文件。

可以参考使用 Windows/MinGW/MSYS 编译 FFmpeg 的编译指南：[CompilationGuide/MinGW](https://trac.ffmpeg.org/wiki/CompilationGuide/MinGW)。



### 1.2. 使用 WSL 编译

WSL 编译相较于 MSYS2 编译的优势是速度更快，但是如果想要支持硬件加速最好使用 MSYS2 编译（尝试使用 WSL 编译没有成功，一直提示找不到依赖）。

打开 `x64 Native Tools Command Prompt for VS 2022` 命令行（根据时间版本和平台），然后输入 `wsl`  进入 Windows Linux 子系统。

```sh
./configure --toolchain=msvc --arch=x86_64 --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-decoder=h264 --enable-encoder=libx264 
make 
make install
```

这里最重要的参数是 `--toolchain=msvc`，指定编译工具链为 MSVC。

通过 `--extra-cxxflags` 和 `--extra-ldflags` 这两个参数，传递符合 cl.exe 标准的 [Windows](https://blog.k-res.net/archives/tag/windows) 头文件、库文件搜索路径进编译链接参数，这样就可以 configure 通过并顺利 make 了。



## 2. Linux 编译

在 Linux 上编译 FFmpeg 相对来说比较简单，以下是一般的步骤：

```sh
# 使用 git 克隆 FFmpeg 存储库
git clone https://git.ffmpeg.org/ffmpeg.git
# 进入 FFmpeg目录并运行 configure 命令以配置编译选项
cd ffmpeg
# 切换分支
git checkout n6.1
# 使用默认配置
./configure
# haoxin codec config（启用 h264、启用 NVIDIA H264、启用 Intel QSV vp9）
./configure --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-decoder=rawvideo --enable-decoder=h264 --enable-decoder=h264_cuvid --enable-decoder=h264_qsv --enable-decoder=vp9_cuvid --enable-decoder=vp9_qsv --enable-encoder=libx264 --enable-encoder=h264_nvenc --enable-encoder=h264_qsv --enable-encoder=vp9_qsv --enable-hwaccel=h264_nvdec --enable-hwaccel=vp9_nvdec --enable-muxer=h264 --enable-demuxer=rawvideo --enable-demuxer=h264 --enable-protocol=file --enable-libx264 --enable-cuda --enable-cuvid --enable-nvenc --enable-libvpl
# 构建和安装
make -j
make install
```

可以参考官方编译指南以获取更多帮助：[Compile FFmpeg for Ubuntu, Debian, or Mint](http://trac.ffmpeg.org/wiki/CompilationGuide/Ubuntu) 、[Compiling FFmpeg on CentOS / RHEL / Fedora](https://trac.ffmpeg.org/wiki/CompilationGuide/Centos)。



## 3. Android 编译

```sh
# 使用 git 克隆 FFmpeg 存储库
git clone https://git.ffmpeg.org/ffmpeg.git
# 进入 FFmpeg目录并运行 configure 命令以配置编译选项
cd ffmpeg
# 切换分支
git checkout n6.1
# set compiler
export CC=/home/cjx/Android/Sdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android34-clang
# 配置
./configure --target-os=android --arch=arm64 --enable-cross-compile --prefix=~/FFmpeg-lib/android_arm64 --enable-gpl --enable-static --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-programs --disable-avdevice --disable-swresample --disable-swscale --disable-postproc --disable-avfilter --disable-everything --enable-decoder=h264 --cc="$CC" --disable-iconv
# 构建和安装
make -j
make install
```



如果 Android ndk 编译提示 `stdin ,stdout, stderr undefine reference`，是因为 23 版本之前实际定义了 `define stderr (&__sF[2])` , 把 *aarch64-linux-android34-clang* 降到 23 之前即可。



## 4. macOS 编译

```sh
# 使用 git 克隆 FFmpeg 存储库
git clone https://git.ffmpeg.org/ffmpeg.git
# 进入 FFmpeg目录并运行 configure 命令以配置编译选项
cd ffmpeg
# 切换分支
git checkout n6.1
# 使用默认配置
./configure --arch=x86_64
./configure --arch=arm64
# 构建和安装
make -j
make install
```



如何使用库文件的时候遇到 `ld64.lld: error: ../../dependencies/lib/haoxinffmpeg/mac/arm64/libavcodec.a(fdctdsp_init_aarch64.o) has version 14.0.0, which is newer than target minimum of 11.0.0` 错误，则需要在配置的时候指定 `macosx-version-min` 参数：

```sh
./configure --extra-cflags="-mmacosx-version-min=11.0" --extra-ldflags="-mmacosx-version-min=11.0"
```



### 4.1. 交叉编译

在 M1 芯片的 macOS 上编译 x86_64 架构的 FFmpeg：

```sh
arch -x86_64 ./configure --arch=x86_64 --extra-cflags="-mmacosx-version-min=10.0" --extra-ldflags="-mmacosx-version-min=10.0"
arch -x86_64 make
arch -x86_64 make install
```



## 5. iOS 编译

```sh
# 使用 git 克隆 FFmpeg 存储库
git clone https://git.ffmpeg.org/ffmpeg.git
# 进入 FFmpeg目录并运行 configure 命令以配置编译选项
cd ffmpeg
# 切换分支
git checkout n6.1
# 配置
export XCRUN_SDK=`echo $PLATFORM | tr '[:upper:]' '[:lower:]'`
export CC="xcrun -sdk $XCRUN_SDK clang"
./configure --target-os=darwin --arch=arm64 --enable-cross-compile --prefix=/Users/cjx/FFmpeg-lib/ios_arm64 --enable-gpl --enable-static --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-programs --disable-avdevice --disable-swresample --disable-swscale --disable-postproc --disable-avfilter --disable-everything --enable-decoder=h264 --cc="$CC" --extra-cflags="-arch arm64 -mios-version-min=11.0 -fembed-bitcode" --extra-ldflags="-arch arm64 -mios-version-min=11.0 -fembed-bitcode"
# 构建和安装
make -j
make install
```

参考：https://github.com/kewlbear/FFmpeg-iOS-build-script/blob/master/build-ffmpeg.sh



## 6. 裁剪

这里说的裁剪是指在编译 FFmpeg 时通过配置编译参数选择是否编译生成指定的库和工具，以及支持哪些编解码格式。

在 FFmpeg 源码路径下，运行 `./configure --help`，会提示每个编译参数的含义。

```sh
# 执行默认的配置（也可以用于查看默认支持的参数）
./configure
# 帮助，输出所有参数及参数含义
./configure --help
# 列出所有解码器
./configure --list-decoders
# 列出所有编码器
./configure --list-encoders
# 列出所有硬件加速器
./configure --list-hwaccels
# 列出所有合流器
./configure --list-muxers
# 列出所有分流器
./configure --list-demuxers
# 列出所有过滤
./configure --list-filters

# show all available parsers
./configure --list-parsers
# show all available protocols
./configure --list-protocols      
# show all available bitstream filters
./configure --list-bsfs             
# show all available input devices
./configure --list-indevs  
# show all available output devices
./configure --list-outdevs  
```

正常编译时，在 `./configure` 后附加上述编译配置参数，根据项目所需禁用或启用相关组件，达到裁剪 FFmpeg 的目的。下面是一个示例：

```sh
# 全部禁用
./configure --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything
# 编译
make
```



## 7. 硬件加速

Fmpeg 所支持的硬件加速方案，粗略以各 OS 厂商和芯片厂商特定方案以及行业联盟定义的标准来分为以下 3 类：

- 以操作系统分：Windows，Linux，macOS，Android；
- 以芯片厂商的特定方案分：Intel，AMD，Nvidia 等；
- 以行业标准或事实标准分：OpenMAX 与 OpenCL、Vulkan、OpenGL 及 CUDA 等。



### 7.1. 基于 OS 的硬件加速方案

**1. Windows：Direct3D 9 DXVA2 /Direct3D 11 Video API/DirectShow /Media Foundation**

在 Windows 上，有 Direct3D 9 DXVA2、Direct3D 11 Video API、DirectShow、Media Foundation 等框架 API。

DXVA 2 API 需要 Windows Vista 或更高版本的支持。为了使用 DXVA 功能，基本上只能根据需要选择使用 DireciShow 或者 MediaFoundation。另外需要注意的是，DXVA/DXVA 2/DXVA-HD 只定义了解码加速、后处理加速，并未定义编码加速，如果想从 Windows 层面加速编码的话，只能选择 Media Foundation 或者特定芯片厂商的编码加速实现。现在，FFmpeg 只支持 DXVA2 的硬件加速解码，并未支持 DXVA-HD 加速的后处理和基于 Media Foundation 硬件加速的编码。

**2. Linux：VDPAU/VAAPI/V4L2 及 M2M**

Linux上的硬件加速接口，经历了一个漫长的演化过程，最终的结果是 VDPAU（https://http.download.nvidia.com/XFree86/vdpau/doxygen/html/index.html）与 VAAPI（https://github.com/intel/libva）共存这样一个现状，而这两个API其后的力量，则分别是支持 VDPAU 的 Nvidia 和支持 VA-API 的 Intel，另一个熟悉的芯片厂商 AMD，实际上同时提供过基于 VDPAU 和 VA-API 的支持。另外，对照 VDPAU 与 VA-API 可知，VDPAU 仅定义了解码部分的硬件加速，缺少了编码部分的加速（解码部分也缺乏 VP8/VP9 的支持，且 API 的更新状态似乎也比较慢）。

**3. macOS/iOS：VideoToolbox**

**4. Android：MediaCodec**



### 7.2. NVIDIA GPU 硬件加速

所有 NVIDIA® GPUs 从 Kepler 一代开始支持全加速硬件视频编码和解码。硬件编码器和硬件解码器分别称为 NVENC 和 NVDEC。

NVENC 和 NVDEC 的硬件能力通过 API（以下简称 NVENCODE API 和 NVDECODE API）暴露在 NVIDIA 视频编解码 SDK 中，用户可以通过 API 访问 NVENC 和NVDEC 的硬件加速能力。NVENC 和 NVDEC 可以有效地与 FFmpeg 一起使用，以显着加快视频解码，编码和端到端转码。

支持 NVIDIA GPU 加速的 FFmpeg 需要 Linux 或 Windows 操作系统，并支持 NVIDIA GPU。有关支持的 GPU 列表，可以参阅 https://developer.nvidia.com/nvidia-video-codec-sdk。



#### 7.2.1. 需求

FFmpeg 支持 Windows 和 Linux。FFmpeg 已在 Microsoft Visual Studio 2013 SP2 及以上版本(Windows)、MinGW (msys2-x86_64-20161025) (Windows) 和gcc 4.8 及以上版本(Linux)编译器下进行编译和测试。

对于 NVIDIA 加速的 FFmpeg 构建，FFmpeg 需要单独的 git 存储库 nvcodec-headers。

要编译 FFmpeg，CUDA工具包必须安装在系统上，尽管 CUDA 工具包不需要运行 FFmpeg 编译的二进制文件。

在使用 FFmpeg 之前，建议参考 FFmpeg 文档，注意它使用的视频编解码器 SDK 的版本，并确保安装了该版本的视频编解码器 SDK 所需的最小驱动程序。



#### 7.2.2 Linux 编译

所有 Linux 平台都支持带有 NVIDIA GPU 加速的 FFmpeg。要在 Linux 上编译 FFmpeg，请执行以下操作：

```sh
# nv-codec-headers
#git clone https://github.com/FFmpeg/nv-codec-headers
# https://git.videolan.org/?p=ffmpeg/nv-codec-headers.git;a=summary
git clone https://git.videolan.org/git/ffmpeg/nv-codec-headers.git
cd nv-codec-headers
make
sudo make install

# nvidia-cuda-toolkit
sudo apt install nvidia-cuda-toolkit

# FFmpeg
cd FFmpeg
./configure --enable-nonfree --enable-cuda-nvcc --enable-libnpp --extra-cflags=-I/usr/local/cuda/include --extra-ldflags=-L/usr/local/cuda/lib64 --disable-static --enable-shared
make
sudo make install
```



#### 7.2.3. Windows 编译

所有 Windows 平台都支持带有 NVIDIA GPU 加速的 FFmpeg，Nvidia 官网上推荐使用 Media Autobuild Suite 进行编译，但是这样不够灵活，无法对 FFmpeg 进行裁剪。

在 Windows 平台和 Linux 平台的编译相差无几，都需要安装 *nv-codec-headers*。

~~需要安装 NVIDIA CUDA，安装完成后在控制台执行 `nvcc --version` 查看 nvcc 版本。~~

~~下载 [NVIDIA Video Codec SDK](https://developer.nvidia.com/video-codec-sdk)~~

```sh
# nv-codec-headers
#git clone https://github.com/FFmpeg/nv-codec-headers
# https://git.videolan.org/?p=ffmpeg/nv-codec-headers.git;a=summary
git clone https://git.videolan.org/git/ffmpeg/nv-codec-headers.git
cd nv-codec-headers
make
sudo make install

# FFmpeg
cd FFmpeg
PKG_CONFIG_PATH="/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH" ./configure --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-decoder=h264_cuvid --enable-encoder=h264_nvenc --enable-hwaccel=h264_nvdec --enable-cuda --enable-cuvid --enable-nvenc
make
sudo make install
```

其中，`/usr/local/lib/pkgconfig` 为 `ffnvcodec.pc` 所在的路径。



#### 7.2.4. 测试

```sh
ffmpeg.exe -hwaccel cuda -f rawvideo -pix_fmt yuv420p -s 1280x720 -i input.yuv -c:v h264_nvenc output.h264
```



### 7.3. Intel QSV 硬件加速

#### 7.3.1. Windows 编译

在 Windows 上编译 FFmpeg 和 QSV 需要 MSYS2。



##### 7.3.1.1. 构建 Libmfx

**libmfx 已经废弃了，官方推荐使用 libvpl**，这里只是把它顺带一起整理出来。

```sh
git clone https://github.com/lu-zero/mfx_dispatch.git
autoreconf -i 
./configure --prefix=/usr/local/libmfx
make -j8 && make install
```

编译过程中会遇到下列错误，只需按下面的方法修改即可。

```
autoreconf -i caused error:
Makefile.am:54: error: 'libintel_gfx_api-x64.a' is not a standard libtool library name
Makefile.am:54: did you mean 'libintel_gfx_api-x64.la'?
Makefile.am:51: error: 'libintel_gfx_api-x86.a' is not a standard libtool library name
Makefile.am:51: did you mean 'libintel_gfx_api-x86.la'?
Solution: Change the File extension to ‘la’ of line 51 and line 54 in Makefile.am
# 则需要修改
libintel_gfx_api-x86.a -> libintel_gfx_api-x86.la
libintel_gfx_api-x64.a -> libintel_gfx_api-x64.la
```



##### 7.3.1.2. 构建 Libvpl

OneVPL 是 MediaSDK (libmfx) 的继承者，建议在 Gen12+ 以上图形平台如 TigerLake, Alderlake 及以上使用。FFmpeg支持 libvpl 的 OneVPL。

```sh
git clone https://github.com/oneapi-src/oneVPL.git
cd <vpl-repo-clone-location>
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX=E:/msys64/usr/local/vpl ..
# 32 bit
# cmake -DCMAKE_INSTALL_PREFIX=E:/msys64/usr/local/vpl32 -A Win32 ..
# 构建 debug 版本
#cmake --build . --config Debug --target install 
# 构建 release 版本
cmake --build . --config Release --target install
```

生成的文件将位于目录 E:/msys64/usr/local/vpl 中，其中包括 include、lib 和 dll文件。



##### 7.3.1.3. 构建 OpenCL

FFmpeg 包括 OpenCL 视频过滤器组，以便编译这些过滤器。

您需要在 Windows 平台上使用 `--enable-opencl` 配置FFmpeg，还需要安装 opencl 头文件和 opencl-icd。

```sh
$pacman -S mingw-w64-x86_64-opencl-headers mingw-w64-x86_64-opencl-icd
```

如何不编译滤镜可以忽略。



##### 7.3.1.4. 构建 FFmpeg

在 Windows 平台，需要使用 `--enable-libvpl` 选项来启用 QSV 和 oneVPL 。Libvpl pkgconfig 路径需要手工配置。

```sh
PKG_CONFIG_PATH="/lib/pkgconfig:/usr/local/x264/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/vpl/lib/pkgconfig:$PKG_CONFIG_PATH" ./configure --prefix=/usr/local/ffmpeg --enable-gpl --enable-shared --enable-decoder=h264 --enable-decoder=h264_qsv --enable-decoder=vp9_cuvid --enable-decoder=vp9_qsv --enable-encoder=libx264 --enable-encoder=h264_qsv --enable-encoder=vp9_qsv --enable-hwaccel=h264_d3d11va --enable-hwaccel=h264_d3d11va2 --enable-hwaccel=h264_dxva2 --enable-hwaccel=vp9_d3d11va --enable-hwaccel=vp9_d3d11va2 --enable-hwaccel=vp9_dxva2 --enable-libx264 --enable-dxva2 --enable-d3d11va --enable-libvpl
```

其中 `dxva2` 参数代表使用使用微软的 DXVA（DirectX Video Acceleration 的简称，中文译为视频[硬件加速](https://baike.baidu.com/item/硬件加速/0?fromModule=lemma_inlink)。DXVA是微软公司专门定制的[视频加速](https://baike.baidu.com/item/视频加速/10256205?fromModule=lemma_inlink)规范，它共有两个版本，分别是 DXVA 1.0 和 DXVA 2.0）硬件加速方案。

在 Windows 运行下需要 `libvpl.dll`。



#### 7.3.2. Linux 编译

##### 7.3.2.1. 检测及安装驱动

经过测试，无法在 WSL 和 VMWare 虚拟机上测试，因为无法将 Intel 集成显卡映射到虚拟机上。我们可以使用下面的方法查看系统上是否有  Intel 显卡：

1. **通过命令行使用 `lspci`**：

打开终端，并输入以下命令：

```sh
lscpu
lspci | grep VGA
# 输出如下：
00:02.0 VGA compatible controller: Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor Integrated Graphics Controller (rev 06)
```

这将列出所有已安装的显卡设备（出现 Intel 字样），包括 Intel 集成显卡。

2. 使用 `lshw` 命令**：

`lshw` 命令用于列出系统硬件信息，包括显卡。在终端中输入以下命令：

```sh
sudo lshw -C display
# 输出如下
  *-display                 
       description: VGA compatible controller
       product: Xeon E3-1200 v3/4th Gen Core Processor Integrated Graphics Controller
       vendor: Intel Corporation
       physical id: 2
       bus info: pci@0000:00:02.0
       version: 06
       width: 64 bits
       clock: 33MHz
       capabilities: msi pm vga_controller bus_master cap_list rom
       configuration: driver=i915 latency=0
       resources: irq:30 memory:f7800000-f7bfffff memory:e0000000-efffffff ioport:f000(size=64) memory:c0000-dffff
```

这将列出所有显示控制器的详细信息，包括 Intel 集成显卡。

接下来要判断系统上是否有 Intel Media Driver。

```sh
apt install vainfo
vainfo
# 输出如下：
error: can't connect to X server!
libva info: VA-API version 1.7.0
libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/iHD_drv_video.so
libva info: va_openDriver() returns -1
libva info: Trying to open /usr/lib/x86_64-linux-gnu/dri/i965_drv_video.so
libva info: Found init function __vaDriverInit_1_7
libva info: va_openDriver() returns 0
vainfo: VA-API version: 1.7 (libva 2.7.0)
vainfo: Driver version: Intel i965 driver for Intel(R) Haswell Desktop - 2.4.0
vainfo: Supported profile and entrypoints
      VAProfileMPEG2Simple            : VAEntrypointVLD
      VAProfileMPEG2Simple            : VAEntrypointEncSlice
      VAProfileMPEG2Main              : VAEntrypointVLD
      VAProfileMPEG2Main              : VAEntrypointEncSlice
      VAProfileH264ConstrainedBaseline: VAEntrypointVLD
      VAProfileH264ConstrainedBaseline: VAEntrypointEncSlice
      VAProfileH264Main               : VAEntrypointVLD
      VAProfileH264Main               : VAEntrypointEncSlice
      VAProfileH264High               : VAEntrypointVLD
      VAProfileH264High               : VAEntrypointEncSlice
      VAProfileH264MultiviewHigh      : VAEntrypointVLD
      VAProfileH264MultiviewHigh      : VAEntrypointEncSlice
      VAProfileH264StereoHigh         : VAEntrypointVLD
      VAProfileH264StereoHigh         : VAEntrypointEncSlice
      VAProfileVC1Simple              : VAEntrypointVLD
      VAProfileVC1Main                : VAEntrypointVLD
      VAProfileVC1Advanced            : VAEntrypointVLD
      VAProfileNone                   : VAEntrypointVideoProc
      VAProfileJPEGBaseline           : VAEntrypointVLD
```

上面的输出代表我的机器上有两种驱动，分别是 iHD 和 i965。Intel i965 通常是集成 Intel HD 图形芯片使用的驱动，比如 HD 4000系列等。

如果没有驱动，则需要安装。可以使用下列命令安装：

```sh
sudo apt install intel-media-va-driver-non-free
# 或
sudo apt install intel-media-va-driver
```

或者使用源码安装。



###### 构建 libdrm

libdrm 是构建 Libva 的依赖。

```sh
wget http://xcb.freedesktop.org/dist/libpthread-stubs-0.5.tar.xz
tar xf libpthread-stubs-0.5.tar.xz --one-top-level=libpthread-stubs --strip-components 1
cd libpthread-stubs
./configure --prefix=/usr
make
sudo make install

git clone https://gitlab.freedesktop.org/mesa/drm
cd drm
meson builddir/
sudo ninja -C builddir/ install
```



###### 构建 Libva

Libva 是 VA-API(视频加速API)的实现，VA-API 是一个开源库和 API 规范，它为视频处理提供了对图形硬件加速功能的访问。

```sh
wget https://github.com/intel/libva/archive/refs/tags/2.13.0.tar.gz -O libva.tar.gz
tar zxf libva.tar.gz --one-top-level=libva --strip-components 1 
cd libva
./autogen.sh --prefix=/usr --libdir=/usr/lib/x86_64-linux-gnu
make -j$(nproc) VERBOSE=1
sudo make -j$(nproc) install
sudo ldconfig -vvvv
```



###### 构建 Gmmlib

Gmmlib 是英特尔图形内存管理库，它为 OpenCL 和英特尔媒体驱动程序提供了设备特定的缓存管理图形计算 VAAPI 运行时。

```sh
wget https://github.com/intel/gmmlib/archive/refs/tags/intel-gmmlib-22.0.1.tar.gz 
tar zxf intel-gmmlib-22.0.1.tar.gz --one-top-level=gmmlib --strip-components 1
cd gmmlib
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j$(nproc)
sudo make -j$(nproc) install
```



###### 构建 Intel Media Driver

```sh
wget https://github.com/intel/media-driver/archive/refs/tags/intel-media-22.1.1.tar.gz
tar zxf intel-media-22.1.1.tar.gz --one-top-level=media-driver --strip-components 1
cd media-driver
mkdir build
cd build
cmake .. \
-DBS_DIR_GMMLIB=$PWD/../../gmmlib/Source/GmmLib/ \
-DBS_DIR_COMMON=$PWD/../../gmmlib/Source/Common/ \
-DBS_DIR_INC=$PWD/../../gmmlib/Source/inc/ \
-DBS_DIR_MEDIA=$PWD/../../media-driver \
-DCMAKE_INSTALL_PREFIX=/usr \
-DCMAKE_INSTALL_LIBDIR=/usr/lib/x86_64-linux-gnu \
-DINSTALL_DRIVER_SYSCONF=OFF \
-DLIBVA_DRIVERS_PATH=/usr/lib/x86_64-linux-gnu/dri
make -j$(nproc) 
sudo make -j$(nproc) install
```

构建完成后，导出环境变量，如下所示，或者您可以将它们声明到 *~/.bashrc*：

```
export LIBVA_DRIVERS_PATH=/usr/lib/x86_64-linux-gnu/dri
export LIBVA_DRIVER_NAME=iHD
```



###### 构建 Libva-Utils

ibva-utils 是一个实用程序和示例的集合，用于根据 libva 项目运行 VA-API。比如 Vainfo，它可以用来验证平台支持的特性：

```sh
wget https://github.com/intel/libva-utils/archive/refs/tags/2.13.0.tar.gz -O libva-utils.tar.gz
tar zxf libva-utils.tar.gz --one-top-level=libva-utils --strip-components 1
cd libva-utils
./autogen.sh --prefix=/usr --libdir=/usr/lib/x86_64-linux-gnu
make -j$(nproc)
sudo make -j$(nproc) install
```



###### 构建 Intel Media SDK

英特尔媒体 SDK 是一个 API，用于访问集成图形硬件平台上的硬件加速视频编码，解码和预处理和后处理。请按照以下步骤构建 Media SDK。它将被安装到默认位置 */opt/intel/mediasdk*。

```sh
wget https://github.com/Intel-Media-SDK/MediaSDK/archive/refs/tags/intel-mediasdk-22.1.0.tar.gz
tar zxf intel-mediasdk-22.1.0.tar.gz --one-top-level=MediaSDK --strip-components 1
cd MediaSDK
mkdir build && cd build
cmake ..
make -j$(nproc) 
sudo make -j$(nproc) install
```

安装完成后需要重启系统。



##### 7.3.2.2. 构建 Libvpl

```sh
# https://github.com/intel/libvpl/blob/master/INSTALL.md
git clone https://github.com/intel/libvpl/
cd libvpl
sudo script/bootstrap
script/build
sudo script/install
```



##### 7.3.2.3. 编译 FFmpeg

```sh
# 配置如下
./configure --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-decoder=rawvideo --enable-decoder=h264 --enable-decoder=h264_qsv --enable-decoder=vp9_qsv --enable-encoder=libx264 --enable-encoder=h264_qsv --enable-encoder=vp9_qsv --enable-muxer=h264 --enable-demuxer=rawvideo --enable-demuxer=h264 --enable-protocol=file --enable-filter=scale --enable-libx264 --enable-libvpl
```



##### 7.3.2.4. 测试

```sh
# Windows
ffmpeg.exe -hwaccel qsv -qsv_device 1 -f rawvideo -pix_fmt yuv420p -s 1280x720 -i C:\Users\Administrator\Desktop\FourPeople_1280x720_30.yuv -c:v h264_qsv output.h264

# Linux
ffmpeg -hwaccel qsv -f rawvideo -pix_fmt yuv420p -s 1280x720 -i ~/tmp/FourPeople_1280x720_30.yuv -c:v h264_qsv output.h264 -loglevel trace
```

在 Windows 遇到了一个多显卡的问题。当我机器上有个独立的 NVIDIA 显卡时，接了显示器后，打开设备出现了下列问题：

```
Error creating a MFX session: -9.
Device creation failed: -1313558101.
```

解决方法是添加 `-qsv_device 1` 参数，或者将显示器接到集成显卡的输出口。

可以使用 `ffmpeg -h encoder=h264_qsv` 命令查看 h264_qsv 支持的参数。



### 7.4. AMD GPU 硬件加速

可以使用 AMD Advanced Media Framework 库用于在具有视频编码引擎 （VCE） 的硬件上加速 H.264 和 HEVC（仅限 Windows）编码。

要启用支持，必须从 https://github.com/GPUOpen-LibrariesAndSDKs/AMF.git 获取 AMF 框架头文件（版本 1.4.9+）。

在系统 *include* 路径中创建一个 `AMF/` 目录。 将 `AMF/amf/public/include/` 中的内容复制到该目录中。 然后使用 `--enable-amf` 配置。

amf 编码器的初始化按以下顺序进行： 

1. 尝试通过 DX11 初始化（仅限Windows） ；
2. 尝试通过 DX9 初始化（仅限Windows）；
3. 尝试通过 vulkan 进行初始化。

在 linux amdgru-pro 版本 19.20+ 和 amf-amdgpu-pro 上使用 h.264（AMD VCE） 编码器软件包（amdgru-pro 包含，但不会自动安装）是必需的。此驱动程序可以使用官方 amd 驱动程序存档中的 amdgpu-pro-install 脚本进行安装。



#### 7.4.1. Windows 编译

首先将 *AMF/amf/public/include/* 目录中的内容复制到  */usr/local/include/AMF/* 目录下。

```sh
cd FFmpeg
PKG_CONFIG_PATH="/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH" ./configure --enable-gpl --enable-shared --enable-small --disable-doc --disable-htmlpages --disable-manpages --disable-podpages --disable-txtpages --disable-everything --enable-encoder=h264_amf
make --enable-amf 
sudo make install
```

在 Windows 运行下需要 `amfrt64.dll`。

```sh
# Windows
ffmpeg.exe -f rawvideo -pix_fmt yuv420p -s 1280x720 -i C:\Users\Administrator\Desktop\FourPeople_1280x720_30.yuv -c:v h264_amf output.h264

```



### 7.5. Vulkan 硬件加速

从[Vulkan官网](https://vulkan.lunarg.com/)下载并安装，确保环境变量`VULKAN_SDK`指向安装路径（如`C:\VulkanSDK\<version>`）。

在 MSYS2 的 Mingw64 终端中运行以下命令，启用 Vulkan 支持：

```sh
./configure \
  --prefix=/usr/local \
  --arch=x86_64 \
  --enable-shared \
  --enable-static \
  --enable-vulkan \            # 启用Vulkan动态链接
  --enable-vulkan-static \     # 启用Vulkan静态链接
  --extra-cflags="-I$VULKAN_SDK/Include" \
  --extra-ldflags="-L$VULKAN_SDK/Lib"
```

**关键参数说明**：

- `--enable-vulkan`：动态链接Vulkan库。
- `--enable-vulkan-static`：静态链接Vulkan库，需确保Vulkan的静态库（`.lib`）存在。
- `--extra-cflags`和`--extra-ldflags`：指定Vulkan SDK的头文件和库路径26。

编译完成后使用系列命令验证构建结果：

```sh
ffmpeg -vulkan -version
```

若输出中包含 `--enable-vulkan`，则说明 Vulkan 已启用。

使用支持的 Vulkan 滤镜（如`scale_vulkan`）测试：

```
ffmpeg -i input.mp4 -vf "scale_vulkan=640:480" output.mp4
```



参考文章：

- [FFMPEG 编译与裁剪](https://wx.comake.online/doc/syg27dk2rkls-SSD20X/customer/development/software/Px/zh/multimedia/build.html)
- [Using FFmpeg with NVIDIA GPU Hardware Acceleration](https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html)
- [Building FFmpeg with QSV on Windows and Linux Intel Platform](https://www.intel.com/content/www/us/en/content-details/728030/building-ffmpeg-with-qsv-on-windows-and-linux-intel-platform.html)
- [Build FFmpeg with AMF Support](https://github.com/GPUOpen-LibrariesAndSDKs/AMF/wiki/Build-FFmpeg-with-AMF-Support)
- [AMF HW Acceleration in FFmpeg](https://github.com/GPUOpen-LibrariesAndSDKs/AMF/wiki/FFmpeg-and-AMF-HW-Acceleration)
- [AMF Encoder Settings and Tuning in FFmpeg](https://github.com/GPUOpen-LibrariesAndSDKs/AMF/wiki/AMF%20Encoder%20Settings%20and%20Tuning%20in%20FFmpeg)



